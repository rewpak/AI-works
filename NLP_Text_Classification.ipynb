{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rewpak/AI-works/blob/main/NLP_Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 6. Natural Language Processing\n",
        "# Task 6.2 Text Classification\n",
        "# Problem Descriptions\n",
        "\n",
        "The task is to develop a text classification model for a dataset consisting of messages from 20 news groups, covering diverse topics such as comp.graphics, rec.sport.hockey, sci.space, talk.religion.misc, and others. The objective is to automatically categorize these messages into their respective news groups based on their content.\n",
        "\n",
        "Text Classification consist of the following steps:\n",
        "\n",
        "1. Collection of texts with class labels:\n",
        "\n",
        "   1. rec.sport.hockey\n",
        "   2. talk.religion.misc\n",
        "   3. comp.graphics\n",
        "   4. sci.space\n",
        "\n",
        "2. Split the data into training set and testing set:\n",
        "\n",
        "   The training set consists of a collection of text documents from the specified categories: 'rec.sport.hockey', 'talk.religion.misc', 'comp.graphics', and 'sci.space'.\n",
        "\n",
        "   \n",
        "\n",
        "3. Extract the word count features\n",
        "\n",
        "  tf: term frequency\n",
        "\n",
        "  tf-idf: tf weighted by inverse document frequency\n",
        "\n",
        "4. Build the naïve Bayes classifier from the training set:\n",
        "\n",
        "   For this task involving discrete data, we employ a Multinomial Naïve Bayes classifier. The choice of this classifier is apt for text classification due to its simplicity and effectiveness with word count features.\n",
        "\n",
        "5. Apply the classifier on the testing data set:\n",
        "\n",
        "   The Naïve Bayes classifier is built using the training set, and then it's applied to the testing data set to make predictions.\n",
        "\n",
        "6. Evaluate the performance:\n",
        "\n",
        "  The final step involves evaluating the model's performance. Common metrics such as accuracy, precision, recall, and F1-score are employed to assess how well the classifier distinguishes between positive and negative sentiments."
      ],
      "metadata": {
        "id": "5EuIsPL1Ah4Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOQvTfSeBLUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c4007f-f7b4-4b43-f7f0-cf7ad80f9533"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "fetch_20newsgroups(subset='train')[\"target_names\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH4teCzlBXT_"
      },
      "source": [
        "# Get the training dataset for the specified categoires\n",
        "categories = ['rec.motorcycles', 'talk.politics.guns',\n",
        "              'comp.sys.mac.hardware', 'sci.crypt']\n",
        "training_data = fetch_20newsgroups(subset='train', categories=categories)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czsV4bIXBvQk",
        "outputId": "34840533-f422-4924-8491-6421e91308b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create the tf-idf transformer\n",
        "tfidf = TfidfVectorizer(use_idf=True)\n",
        "# tfidf = TfidfVectorizer(use_idf=False)\n",
        "training_tfidf = tfidf.fit_transform(training_data.data)\n",
        "print(training_tfidf.shape)\n",
        "\n",
        "# Train a Multinomial Naive Bayes classifier\n",
        "classifier = MultinomialNB().fit(training_tfidf, training_data.target)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2317, 36913)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myGwhvndBvHj",
        "outputId": "f3681d14-9a4e-4609-c4b2-7660b334598f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "testing_data = fetch_20newsgroups(subset='test', categories=categories)\n",
        "testing_tfidf = tfidf.transform(testing_data.data)\n",
        "predictions = classifier.predict(testing_tfidf)\n",
        "print(metrics.classification_report(testing_data.target, predictions, target_names=categories))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       precision    recall  f1-score   support\n",
            "\n",
            "      rec.motorcycles       0.99      0.91      0.95       385\n",
            "   talk.politics.guns       0.98      0.96      0.97       398\n",
            "comp.sys.mac.hardware       0.90      0.99      0.94       396\n",
            "            sci.crypt       0.96      0.96      0.96       364\n",
            "\n",
            "             accuracy                           0.95      1543\n",
            "            macro avg       0.96      0.95      0.95      1543\n",
            "         weighted avg       0.96      0.95      0.95      1543\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aumqFItjFPYg"
      },
      "source": [
        "errors = [i for i in range(len(predictions)) if predictions[i] != testing_data.target[i]]\n",
        "\n",
        "for i, post_id in enumerate(errors[:5]):\n",
        "  print(\"------------------------------------------------------------------\")\n",
        "  print(\"%s --> %s\\n\" %(testing_data.target_names[testing_data.target[post_id]],\n",
        "                      testing_data.target_names[predictions[post_id]]))\n",
        "  print(testing_data.data[post_id])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussions\n",
        "\n",
        "In this task, our text classification model did pretty well overall. It accurately predicted topics like rec.sport.hockey, talk.religion.misc, and comp.graphics most of the time. However, it struggled a bit with sci.space, especially in recalling all relevant documents.\n",
        "\n",
        "1. For rec.sport.hockey, it was correct 97% of the time (Precision), and it found 90% of all relevant documents (Recall).\n",
        "\n",
        "2. Talk.religion.misc was even better, with 93% precision and 99% recall.\n",
        "\n",
        "3. Comp.graphics had 83% precision and 98% recall.\n",
        "\n",
        "4. Sci.space had perfect precision (100%) but only found 72% of the relevant documents.\n",
        "\n",
        "\n",
        "For new groups from data set I got the following results:\n",
        "\n",
        "It accurately predicted topics like rec.motorcycles, talk.politics.guns, comp.sys.mac.hardware, and sci.crypt with high precision and recall.\n",
        "\n",
        "1. For rec.motorcycles, it was correct 99% of the time (Precision), and it found 91% of all relevant documents (Recall).\n",
        "\n",
        "2. Talk.politics.guns had 98% precision and 96% recall.\n",
        "\n",
        "3. Comp.sys.mac.hardware achieved 90% precision and 99% recall.\n",
        "\n",
        "4. Sci.crypt had 96% precision and 96% recall.\n",
        "\n",
        "Overall accuracy was 92% and 95%, meaning it made correct predictions about 92% and 95% for both groups of categories. This suggests that our model is effective in handling a variety of topics, demonstrating strong precision and recall scores."
      ],
      "metadata": {
        "id": "qWh8zi-GrnQM"
      }
    }
  ]
}